{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c55e025",
   "metadata": {},
   "source": [
    "# DATA ENGINEERING ETL PIPELINE - XETRA DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d085730",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Onject Oriented Programming Example\n",
    "\n",
    "Aim:\n",
    "Write a production ready ETL pipeline using python and pandas.\n",
    "\n",
    "Overview:\n",
    "Xetra is a German stock exchange based in Frankfurt operated by Deutsche Börse Group. \n",
    "Data related to daily trading activity is stored publicly on the Amazon S3 database. \n",
    "(Update - as of July 2022 the data is no longer available. An archival S3 database will be used) \n",
    "\n",
    "Task:\n",
    "- Use jupyter notebook as a protoyping tool.\n",
    "- Request and extract source data from cloud based web services.\n",
    "- Use list comprehension to read and consolidate multiple source files.\n",
    "- Utilise pandas package tools to facilitate ETL process.\n",
    "- Design and stucture code using object oriented programming techniques. \n",
    "\n",
    "Below outlines the steps to be performed:\n",
    "    \n",
    "    1) Create adapter layer to handle access to API and web service infrastructure:\n",
    "        - Connect, read and write to external data sources.\n",
    "        - Use datetime filtering to specify range and exclude previously processed dates.\n",
    "       \n",
    "    2) Create application layer to handle ETL pipeline:\n",
    "        - Function to EXTRACT bucket data via list comprehension.\n",
    "        - Function to TRANSFORM bucket data using pandas functions. \n",
    "        - Function to LOAD transformed data to Amazon S3 target bucket. \n",
    "        \n",
    "    3) Create main() to serve as program entry point: \n",
    "        - Define user parameters and configurations.\n",
    "        - Run ETL application.\n",
    "        - Load transformed data into private S3 bucket.\n",
    "        - Read data from private S3 bucket to verify ETL pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1e289",
   "metadata": {},
   "source": [
    "# Define Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66eb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to be imported\n",
    "import boto3 #AWS service management package.\n",
    "import pandas as pd #Data analysis library.\n",
    "from io import StringIO #String buffer to read CSV files.\n",
    "from io import BytesIO #Bytes buffer to read PARQUET files.\n",
    "from datetime import datetime, timedelta #Facilitate calulations relating to day of trade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c54097",
   "metadata": {},
   "source": [
    "# Adapter Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04eabf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to convert bucket data from csv into pandas dataframe.\n",
    "def read_csv_to_df (bucket, key, decding = 'utf-8', sep =','):\n",
    "    csv_obj = bucket.Object(key=key).get().get('Body') #Read data element from list.\n",
    "    csv_obj = csv_obj.read().decode('utf-8') #Store into to csv object in utf-8 format.\n",
    "    in_buf = StringIO(csv_obj) #Buffer to store csv object as string data.\n",
    "    df = pd.read_csv(in_buf, delimiter=sep) #Read data into pandas data frame.\n",
    "    return df\n",
    "\n",
    "#Method to write output df to target S3 bucket as a parquet file.\n",
    "def write_df_to_S3(bucket, df, key ):\n",
    "    out_buf = BytesIO() #Buffer to store df object to parquet data. \n",
    "    df.to_parquet(out_buf, index=False) #Write df to parquet buffer.\n",
    "    bucket.put_object(Body=out_buf.getvalue(),Key=key) #Store data into S3 bucket\n",
    "    return True  \n",
    "\n",
    "#Method to return list of files in bucket filtered by date. \n",
    "def list_files_in_prefix(bucket, prefix):\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48610e3",
   "metadata": {},
   "source": [
    "# Application Layer (Non-Core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4ca79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to return list of files in bucket between minimum filtering date and today's date.\n",
    "def return_date_list(bucket, arg_date, arg_date_format): \n",
    "    #Min_date is one less than arg_date as previous calender day required for trade calculations.\n",
    "    min_date = datetime.strptime(arg_date, arg_date_format) \n",
    "    min_date = min_date.date()- timedelta(days=1)   \n",
    "    #Store today's date and filter by selected date range.         \n",
    "    today = datetime.today().date()\n",
    "    return_date_list = [(min_date + timedelta(days=x)).strftime(arg_date_format)for x in range (0 , (today - min_date).days + 1)]\n",
    "    return return_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bd1be096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set date format and values.\n",
    "arg_date_format = '%Y-%m-%d'\n",
    "arg_date = '2021-12-20'\n",
    "today_date = '2021-12-21'  \n",
    "\n",
    "#Read metafile that contains list of previously processed dates into dataframe. \n",
    "trg_bucket = 'xetra-probe' \n",
    "s3 = boto3.resource('s3') \n",
    "bucket_trg = s3.Bucket(trg_bucket)\n",
    "meta_key = 'meta_file.csv'  \n",
    "df_meta = read_csv_to_df(bucket_trg, meta_key )\n",
    "\n",
    "#Min date is the previous day of trade before the argument date. Required for percentage change calculations. \n",
    "min_date = datetime.strptime(arg_date, arg_date_format).date() - timedelta(days=1) \n",
    "\n",
    "#Return list of dates between min_date and today_date).\n",
    "today = datetime.strptime(today_date, arg_date_format).date()\n",
    "return_date_list = [(min_date + timedelta(days=x))for x in range (0 , (today - min_date).days + 1)]\n",
    "\n",
    "#Store processed dates from metafile into a set. \n",
    "meta_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "\n",
    "#Unique values in return_date_list when compared to meta_dates indicates dates to extract from S3 data.   \n",
    "dates_to_extract = set(return_date_list[1:]) - meta_dates\n",
    "\n",
    "if dates_to_extract:\n",
    "    #Recalculate min_date.  \n",
    "    min_date = min(set(return_date_list[1:]) - meta_dates)- timedelta(days=1)\n",
    "    #Filter return dates from source data based on verified min_date.\n",
    "    return_dates = [date.strftime(arg_date_format) for date in return_date_list if date >= min_date]\n",
    "    return_min_date = arg_date\n",
    "else: \n",
    "    return_dates = []\n",
    "    return_min_date = datetime(9999,1,1).date() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5b4b9",
   "metadata": {},
   "source": [
    "# Application Layer (Core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70a0f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to extract bucket data. \n",
    "def extract_bucket_data(bucket, date_list):\n",
    "    #Extract list of csv files from bucket by date prefix. \n",
    "    files = [key for date in date_list for key in list_files_in_prefix(bucket, date)]\n",
    "    #Read body of extracted csv files into master dataframe.\n",
    "    df = pd.concat([read_csv_to_df(bucket,obj) for obj in files], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "#Method to transform bucket data. \n",
    "def transform_bucket_data(df,columns_use,arg_date):\n",
    "    #Method to reove unecessary columns and missing values from data.\n",
    "    df = df.loc[:,columns_use] #Remove unecessary columns \n",
    "    df.dropna(inplace=True) #Drop all missing values from the dataset.\n",
    "    df = df.reset_index(drop=True) #Reset the column index.\n",
    "    df.shape #Check if there was any filtering (should match table dimensions).\n",
    "    \n",
    "    #Get opening price per ISIN on a particular day.  \n",
    "    df['OpeningPrice'] = df.sort_values('Time').groupby(['ISIN','Date'])['StartPrice'].transform('first')\n",
    "\n",
    "    #Get closing price per ISIN on a particular day. \n",
    "    df['ClosingPrice'] = df.sort_values('Time').groupby(['ISIN','Date'])['EndPrice'].transform('last')\n",
    "\n",
    "    #Aggregate data per ISIN on a particular day.\n",
    "    df = df.groupby(['ISIN','Date'], as_index = False).agg(OpeningPriceEUR = ('OpeningPrice', 'min'),ClosingPriceEUR = ('ClosingPrice', 'min'), MinPriceEUR = ('MinPrice', 'min'), MaxPriceEUR = ('MaxPrice', 'max'), DailyTradedVolume = ('TradedVolume', 'sum'))\n",
    "\n",
    "    #Percentage change in closing price between current and pervious day of trade. \n",
    "    df['PrevClosingPriceEUR'] = df.sort_values(by = 'Date').groupby(['ISIN'])['ClosingPriceEUR'].shift(1)\n",
    "    df['DeltaPrevClosingPriceEUR%'] = (df['ClosingPriceEUR'] - df['PrevClosingPriceEUR'])/df['PrevClosingPriceEUR']*100\n",
    "\n",
    "    #Round aggregated data. \n",
    "    df = df.round(decimals = 2)\n",
    "\n",
    "    #Filter output by specified by argument date\n",
    "    df = df[df['Date']>=arg_date]\n",
    "    return df\n",
    "\n",
    "#Method to load transformed bucket data.\n",
    "def load_bucket_data(bucket, df, bucket_key, bucket_format):\n",
    "    #Parametised key name for Amazon target bucket. \n",
    "    bucket_key = bucket_key + datetime.today().strftime('%Y%m%d_%H%M%S') + bucket_format\n",
    "    write_df_to_S3(bucket, df, bucket_key)\n",
    "    return True\n",
    "\n",
    "#ETL function. \n",
    "def etl_report(src_bucket, trg_bucket, date_list, columns, arg_date, trg_key, trg_format):\n",
    "    df = extract_bucket_data(src_bucket, date_list)\n",
    "    df = transform_bucket_data(df,columns_use,arg_date)\n",
    "    df = load_bucket_data(trg_bucket, df, trg_bucket_key, trg_bucket_format)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa2206a",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "303eae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #User defined parameters and configurations. \n",
    "    arg_date = '2022-12-18' #Bucket filtering argument.\n",
    "    arg_date_format = '%Y-%m-%d' #Date format.\n",
    "    src_bucket = 'xetra-1234' #Source data bucket name\n",
    "    trg_bucket = 'xetra-probe'#Target data bucket name\n",
    "    trg_bucket_key = 'xetra_daily_report' #String to prepend target bucket name.\n",
    "    trg_bucket_format = '.parquet' #String to append target bucket name.\n",
    "    columns_use = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "    \n",
    "    #Initialise connections and create bucket instances from Amazon S3 resource.\n",
    "    s3 = boto3.resource('s3') \n",
    "    bucket_src = s3.Bucket(src_bucket)\n",
    "    bucket_trg = s3.Bucket(trg_bucket)\n",
    "    \n",
    "    #Run ETL pipeline application.\n",
    "    date_list = return_date_list(bucket_src, arg_date, arg_date_format)\n",
    "    etl_report(bucket_src, bucket_trg, date_list, columns_use, arg_date, trg_bucket_key, trg_bucket_format)\n",
    "    \n",
    "    #Verify output by reading data back into workflow. \n",
    "    for obj in bucket_trg.objects.all():\n",
    "        prq_obj = bucket_trg.Object(key=obj.key).get().get('Body').read()\n",
    "        data = BytesIO(prq_obj)\n",
    "        df_report = pd.read_parquet(data)\n",
    "    \n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb4660ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>OpeningPriceEUR</th>\n",
       "      <th>ClosingPriceEUR</th>\n",
       "      <th>MinPriceEUR</th>\n",
       "      <th>MaxPriceEUR</th>\n",
       "      <th>DailyTradedVolume</th>\n",
       "      <th>PrevClosingPriceEUR</th>\n",
       "      <th>DeltaPrevClosingPriceEUR%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>38.85</td>\n",
       "      <td>38.60</td>\n",
       "      <td>38.60</td>\n",
       "      <td>38.85</td>\n",
       "      <td>153</td>\n",
       "      <td>39.35</td>\n",
       "      <td>-1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>38.85</td>\n",
       "      <td>38.60</td>\n",
       "      <td>38.60</td>\n",
       "      <td>38.85</td>\n",
       "      <td>153</td>\n",
       "      <td>38.60</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.90</td>\n",
       "      <td>300</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.90</td>\n",
       "      <td>300</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT0000606306</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>25.02</td>\n",
       "      <td>25.06</td>\n",
       "      <td>24.72</td>\n",
       "      <td>25.40</td>\n",
       "      <td>8382</td>\n",
       "      <td>24.80</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>XS2314660700</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>21.32</td>\n",
       "      <td>21.50</td>\n",
       "      <td>20.98</td>\n",
       "      <td>21.56</td>\n",
       "      <td>241</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>XS2376095068</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>35.72</td>\n",
       "      <td>35.37</td>\n",
       "      <td>35.00</td>\n",
       "      <td>35.72</td>\n",
       "      <td>2140</td>\n",
       "      <td>36.91</td>\n",
       "      <td>-4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>XS2376095068</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>35.72</td>\n",
       "      <td>35.37</td>\n",
       "      <td>35.00</td>\n",
       "      <td>35.72</td>\n",
       "      <td>2140</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>-4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6448 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN        Date  OpeningPriceEUR  ClosingPriceEUR  MinPriceEUR  \\\n",
       "0     AT000000STR1  2022-12-18            38.85            38.60        38.60   \n",
       "1     AT000000STR1  2022-12-19            38.85            38.60        38.60   \n",
       "2     AT00000FACC2  2022-12-18             8.86             8.83         8.83   \n",
       "3     AT00000FACC2  2022-12-19             8.86             8.83         8.83   \n",
       "4     AT0000606306  2022-12-18            25.02            25.06        24.72   \n",
       "...            ...         ...              ...              ...          ...   \n",
       "6443  XS2314660700  2022-12-19            21.32            21.50        20.98   \n",
       "6444  XS2376095068  2022-12-18            35.72            35.37        35.00   \n",
       "6445  XS2376095068  2022-12-19            35.72            35.37        35.00   \n",
       "6446  XS2434891219  2022-12-18             3.59             3.55         3.55   \n",
       "6447  XS2434891219  2022-12-19             3.59             3.55         3.55   \n",
       "\n",
       "      MaxPriceEUR  DailyTradedVolume  PrevClosingPriceEUR  \\\n",
       "0           38.85                153                39.35   \n",
       "1           38.85                153                38.60   \n",
       "2            8.90                300                 9.12   \n",
       "3            8.90                300                 8.83   \n",
       "4           25.40               8382                24.80   \n",
       "...           ...                ...                  ...   \n",
       "6443        21.56                241                21.50   \n",
       "6444        35.72               2140                36.91   \n",
       "6445        35.72               2140                35.37   \n",
       "6446         3.59                  0                 3.70   \n",
       "6447         3.59                  0                 3.55   \n",
       "\n",
       "      DeltaPrevClosingPriceEUR%  \n",
       "0                         -1.91  \n",
       "1                          0.00  \n",
       "2                         -3.18  \n",
       "3                          0.00  \n",
       "4                          1.05  \n",
       "...                         ...  \n",
       "6443                       0.00  \n",
       "6444                      -4.19  \n",
       "6445                       0.00  \n",
       "6446                      -4.11  \n",
       "6447                       0.00  \n",
       "\n",
       "[6448 rows x 9 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run main function\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
