{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f609d3a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nDATA ENGINEERING ETL PIPELINE - XETRA DATASET\\n\\n2: Reading multiple files and cleansing data.\\n\\nAim:\\nWrite a production ready ETL pipeline using python and pandas.\\n\\nOverview:\\nXetra is a German stock exchange based in Frankfurt operated by Deutsche Börse Group. \\nData related to daily trading activity is stored publicly on the Amazon S3 database. \\n(Update - as of July 2022 the data is no longer available. An archival S3 database will be used) \\n\\nTask:\\nUse jupyter notebook as a protoyping tool to extract and transform source data.\\nRequest and extract source data from cloud based web services.\\nUse loops and iteration to read and consolidate multiple source files.\\nFamiliarise with pandas package functions to clean output data. \\n\\nBelow outlines the steps to be performed:\\n    \\n    1) First import the necessary libraries and functions for the project.\\n    2) Create variables to define the Amazon S3 cloud resource we're going to call. \\n    3) Retrieve the trading data from amazon S3 bucket labelled 'xetra-1234'.\\n    4) Filter multiple xetra buckets by date concatenate data elements into bucket list.\\n    5) Extract body of data (csv) and read into into pandas dataframe:\\n        - Initialisation step, where csv column template is taken from first element of bucket list.\\n        - Iteration step, where remaining list elements are read and appended to pandas dataframe. \\n    6) Print column names and remove any that are unecessary.\\n    7) Remove any record with missing values. \\n    8) Print data frame objet.\\n    \\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "DATA ENGINEERING ETL PIPELINE - XETRA DATASET\n",
    "\n",
    "2: Reading multiple files and cleansing data.\n",
    "\n",
    "Aim:\n",
    "Write a production ready ETL pipeline using python and pandas.\n",
    "\n",
    "Overview:\n",
    "Xetra is a German stock exchange based in Frankfurt operated by Deutsche Börse Group. \n",
    "Data related to daily trading activity is stored publicly on the Amazon S3 database. \n",
    "(Update - as of July 2022 the data is no longer available. An archival S3 database will be used) \n",
    "\n",
    "Task:\n",
    "Use jupyter notebook as a protoyping tool to extract and transform source data.\n",
    "Request and extract source data from cloud based web services.\n",
    "Use loops and iteration to read and consolidate multiple source files.\n",
    "Familiarise with pandas package functions to clean output data. \n",
    "\n",
    "Below outlines the steps to be performed:\n",
    "    \n",
    "    1) First import the necessary libraries and functions for the project.\n",
    "    2) Create variables to define the Amazon S3 cloud resource we're going to call. \n",
    "    3) Retrieve the trading data from amazon S3 bucket labelled 'xetra-1234'.\n",
    "    4) Filter multiple xetra buckets by date concatenate data elements into bucket list.\n",
    "    5) Extract body of data (csv) and read into into pandas dataframe:\n",
    "        - Initialisation step, where csv column template is taken from first element of bucket list.\n",
    "        - Iteration step, where remaining list elements are read and appended to pandas dataframe. \n",
    "    6) Print column names and remove any that are unecessary.\n",
    "    7) Remove any records with missing values. \n",
    "    8) Print data frame object.\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b66eb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 #AWS service management package.\n",
    "import pandas as pd #Data analysis library.\n",
    "from io import StringIO #String buffer to read CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "999ae088",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3') #Use the Amazon S3 cloud storage resource.\n",
    "bucket = s3.Bucket('xetra-1234') #Create instance of the \"xetra\" data bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c452b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_obj1 = bucket.objects.filter(Prefix='2022-01-28/') #Filter by date and store data as \"bucket_obj1\".\n",
    "bucket_obj2 = bucket.objects.filter(Prefix='2022-02-28/') #Filter by date and store data as \"bucket_obj2\".\n",
    "bucket_objects = [obj for obj in bucket_obj1] + [obj for obj in bucket_obj2]  #Store data into bucket list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9799381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv body of dataset into pandas dataframe - initialisation step:\n",
    "csv_obj_init = bucket.Object(key=bucket_objects[0].key).get().get('Body') #Initialise first element of csv object.\n",
    "csv_obj_init = csv_obj_init.read().decode('utf-8') #Store into csv object in utf-8 format.\n",
    "data = StringIO(csv_obj_init) #Convert csv object from streaming body to string data.\n",
    "df_init = pd.read_csv(data, delimiter=',') #Read data into pandas data frame.\n",
    "df_all = pd.DataFrame(columns=df_init.columns) #Initialise df_all with df_init columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68ee78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv body of dataset into pandas dataframe - iteration step:\n",
    "for obj in bucket_objects:\n",
    "    csv_obj = bucket.Object(key=obj.key).get().get('Body') #Read data element from list.\n",
    "    csv_obj = csv_obj.read().decode('utf-8') #Store into to csv object in utf-8 format.\n",
    "    data = StringIO(csv_obj) #Convert csv object to string data.\n",
    "    df = pd.read_csv(data, delimiter=',') #Read data as pandas data frame.\n",
    "    df_all = pd.concat([df, df_all]) #Concatenate data to one master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cba0345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISIN,Mnemonic,SecurityDesc,SecurityType,Currency,SecurityID,Date,Time,StartPrice,MaxPrice,MinPrice,EndPrice,TradedVolume,NumberOfTrades\\r\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_obj #Print csv object to view columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc15204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unecessary columns by storing required columns in variable and passing as .loc function argument. \n",
    "columns_use = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "df_all = df_all.loc[:,columns_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd5d28eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257248, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.dropna(inplace=True) #Drop all missing values from the dataset.\n",
    "df_all.shape #Check if there was any filtering (should match table dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01048da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>StartPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>EndPrice</th>\n",
       "      <th>TradedVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US98956P1021</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>20:30</td>\n",
       "      <td>113.100</td>\n",
       "      <td>113.100</td>\n",
       "      <td>113.100</td>\n",
       "      <td>113.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US9224171002</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>20:30</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT0005143547</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>20:30</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA0679011084</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>16:00</td>\n",
       "      <td>20.215</td>\n",
       "      <td>20.215</td>\n",
       "      <td>20.185</td>\n",
       "      <td>20.185</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA32076V1031</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>16:00</td>\n",
       "      <td>10.060</td>\n",
       "      <td>10.060</td>\n",
       "      <td>10.060</td>\n",
       "      <td>10.060</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16728</th>\n",
       "      <td>DK0061539921</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>08:59</td>\n",
       "      <td>23.270</td>\n",
       "      <td>23.270</td>\n",
       "      <td>23.270</td>\n",
       "      <td>23.270</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16729</th>\n",
       "      <td>DE000A3E5D56</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>08:59</td>\n",
       "      <td>30.060</td>\n",
       "      <td>30.080</td>\n",
       "      <td>30.060</td>\n",
       "      <td>30.080</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16730</th>\n",
       "      <td>DE000A3E5D64</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>08:59</td>\n",
       "      <td>38.100</td>\n",
       "      <td>38.100</td>\n",
       "      <td>38.100</td>\n",
       "      <td>38.100</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16731</th>\n",
       "      <td>FR0000121147</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>08:59</td>\n",
       "      <td>38.840</td>\n",
       "      <td>38.840</td>\n",
       "      <td>38.840</td>\n",
       "      <td>38.840</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16732</th>\n",
       "      <td>DE000DTR0CK8</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>08:59</td>\n",
       "      <td>31.925</td>\n",
       "      <td>31.925</td>\n",
       "      <td>31.910</td>\n",
       "      <td>31.920</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257248 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISIN        Date   Time  StartPrice  MaxPrice  MinPrice  \\\n",
       "0      US98956P1021  2022-02-28  20:30     113.100   113.100   113.100   \n",
       "1      US9224171002  2022-02-28  20:30      24.600    24.600    24.600   \n",
       "2      IT0005143547  2022-02-28  20:30       3.100     3.100     3.100   \n",
       "0      CA0679011084  2022-02-28  16:00      20.215    20.215    20.185   \n",
       "1      CA32076V1031  2022-02-28  16:00      10.060    10.060    10.060   \n",
       "...             ...         ...    ...         ...       ...       ...   \n",
       "16728  DK0061539921  2022-01-28  08:59      23.270    23.270    23.270   \n",
       "16729  DE000A3E5D56  2022-01-28  08:59      30.060    30.080    30.060   \n",
       "16730  DE000A3E5D64  2022-01-28  08:59      38.100    38.100    38.100   \n",
       "16731  FR0000121147  2022-01-28  08:59      38.840    38.840    38.840   \n",
       "16732  DE000DTR0CK8  2022-01-28  08:59      31.925    31.925    31.910   \n",
       "\n",
       "       EndPrice TradedVolume  \n",
       "0       113.100            0  \n",
       "1        24.600            0  \n",
       "2         3.100            0  \n",
       "0        20.185           60  \n",
       "1        10.060           11  \n",
       "...         ...          ...  \n",
       "16728    23.270           37  \n",
       "16729    30.080          218  \n",
       "16730    38.100           34  \n",
       "16731    38.840           40  \n",
       "16732    31.920         1461  \n",
       "\n",
       "[257248 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all #Print data frame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa1058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
